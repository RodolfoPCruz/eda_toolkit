{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db82e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import set_config\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "503ab793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn will return a pandas dataframe insted of a numpy array\n",
    "set_config(transform_output=\"pandas\")\n",
    "random_state = 42\n",
    "sns.set_style(\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26953fb",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "849ffc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba       = pd.read_csv('../data/nba/nba_salaries.csv')\n",
    "insurance = pd.read_csv('../data/insurance/insurance.csv')\n",
    "airline   = pd.read_csv('../data/airline/train.csv')\n",
    "airbnb    = pd.read_csv('../data/airbnb/listings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ac45f",
   "metadata": {},
   "source": [
    "# Managing outliers one feature at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696011a0",
   "metadata": {},
   "source": [
    "## First Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be8b595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers(df: pd.DataFrame, features_list: list = None, \n",
    "                   outlier_treatment: str = None, output_column: str = None, \n",
    "                   skew_thresold: float = 1):\n",
    "    '''\n",
    "    Detect and treat outliers. Two criteria will be used to detect outliers:\n",
    "        - empirical rule to detect outliers in normal distributions;\n",
    "        - Tukey rule to detect outliers in distributions that are not normal.\n",
    "    A distribution will be considered normal when its skewness is between -1 * skew_thresold and skew_thresold.\n",
    "    One of the two criteria will be used to calculate max_thresh and min_thresh. Values above max_thresh and \n",
    "    values below min_thresh are considered outliers.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe to be cleaned.\n",
    "    features_list : list, optional\n",
    "        The list of features to be cleaned, by default, is None. If None, the function will clean all features.\n",
    "    outlier_treatment : str, optional\n",
    "        The treatment to be applied to outliers, by default, None. Can be 'remove'; 'replace'; 'impute', or None:\n",
    "            - remove: rows containing outliers are completely removed;\n",
    "            - replace: outliers above max_thresh and outliers below min_thresh are replaced by max_thresh and min_thresh, respectively;\n",
    "            - impute: outliers above max_thresh and outliers below min_thresh are imputed using the Iterative imputer method form scikit-learn;\n",
    "            - None: no treatment is applied to outliers.\n",
    "    output_column : str, optional\n",
    "        The name of the output column, by default is None. The output column will not be used when calculating the values to be imputed. \n",
    "        If None, it is considered that the output column is not in df.\n",
    "    skew_thresold : float, optional\n",
    "        The skewness threshold for a distribution to be considered normal, by default 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The cleaned dataframe.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = df.copy()\n",
    "    \n",
    "    if features_list is None:\n",
    "        features_list = df.columns\n",
    "\n",
    "    if outlier_treatment not in ['remove', 'replace', 'impute', None]:\n",
    "        print(f'The outlier_treatment {outlier_treatment} is not valid. No treatment will be applied to outliers.')\n",
    "        outlier_treatment = None\n",
    "\n",
    "    #remove output_column from features_list. The output column can not be used when calculating the values to be imputed\n",
    "    if output_column is not None and output_column in features_list:\n",
    "        features_list_impute_method = features_list.copy()\n",
    "        features_list_impute_method.remove(output_column)\n",
    "    else:\n",
    "        features_list_impute_method = features_list\n",
    " \n",
    "\n",
    "    for feature in features_list:\n",
    "        #test whether the feature is in the dataframe\n",
    "        if feature in df.columns:\n",
    "            #only numeric columns will be cleaned\n",
    "            if pd.api.types.is_numeric_dtype(df[feature]):\n",
    "\n",
    "                #test whether the feature has only one unique value\n",
    "                if df[feature].nunique() == 1:\n",
    "                    print(f'The feature {feature} has only one unique value and was therefore ignored.')\n",
    "\n",
    "                #test whether the feature is binary (only true or false values)\n",
    "                elif (set(df[feature].dropna().unique()).issubset({0, 1}) or\n",
    "                        set(df[feature].dropna().unique()).issubset({True, False})):\n",
    "                    print(f'The feature {feature} is binary (only true or false values) and was therefore ignored.')\n",
    "\n",
    "                # look for outliers\n",
    "                else:\n",
    "                    #test whether the distribution is normal\n",
    "                    skew = df[feature].skew()\n",
    "                    if skew > -1 * skew_thresold and skew < skew_thresold:\n",
    "                        #empirical rule to detect outliers in normal distributions\n",
    "                        min_thresh = df[feature].mean() - 3 * df[feature].std()\n",
    "                        max_thresh = df[feature].mean() + 3 * df[feature].std()\n",
    "                    else: \n",
    "                        #apply the Tukey rule to detect outliers in distributions that are not normal\n",
    "                        q1 = df[feature].quantile(0.25)\n",
    "                        q3 = df[feature].quantile(0.75)\n",
    "                        iqr = q3 - q1 #interquartile range\n",
    "                        max_thresh = q3 + 1.5 * (iqr) \n",
    "                        min_thresh = q1 - 1.5 * (iqr)\n",
    "\n",
    "                    #values above max_thresh and values below min_thresh are considered outliers\n",
    "                    count_max_outlier = len(df.loc[df[feature] > max_thresh])\n",
    "                    count_min_outlier = len(df.loc[df[feature] < min_thresh])\n",
    "                    print(f'The feature {feature} has {count_max_outlier} values above {max_thresh}')\n",
    "                    print(f'The feature {feature} has {count_min_outlier} values below {min_thresh}')\n",
    "\n",
    "                    #deal with outliers\n",
    "                    if count_max_outlier > 0 and outlier_treatment != 'impute':\n",
    "                        if outlier_treatment == 'remove':\n",
    "                            print(f'{count_max_outlier} values above {max_thresh} were removed in feature {feature}')  \n",
    "                            df = df[df[feature] < max_thresh]\n",
    "\n",
    "                        elif outlier_treatment == 'replace':\n",
    "                            if not pd.api.types.is_float_dtype(df[feature]):\n",
    "                                df[feature] = df[feature].astype(float) #convert to float\n",
    "                            print(f'{count_max_outlier} values above {max_thresh} were replaced in feature {feature}')  \n",
    "                            df.loc[df[feature] > max_thresh, feature] = max_thresh\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    if count_min_outlier > 0 and outlier_treatment != 'impute':\n",
    "                        if outlier_treatment == 'remove':\n",
    "                            print(f'{count_min_outlier} values below {min_thresh} were removed in feature {feature}')  \n",
    "                            df = df[df[feature] > min_thresh]\n",
    "                        elif outlier_treatment == 'replace':\n",
    "                            if not pd.api.types.is_float_dtype(df[feature]):\n",
    "                                df[feature] = df[feature].astype(float) #convert to float\n",
    "                            print(f'{count_min_outlier} values below {min_thresh} were replaced in feature {feature}')  \n",
    "                            df.loc[df[feature] < min_thresh, feature] = min_thresh\n",
    "                        else:\n",
    "                            continue\n",
    "                    #impute method\n",
    "                    has_outliers = count_max_outlier > 0 or count_min_outlier > 0\n",
    "                    if outlier_treatment == 'impute' and has_outliers:\n",
    "                        #numeric_columns = df.select_dtypes(include = 'number').columns.to_list()\n",
    "                        df_temp = df.copy()\n",
    "                        df_temp.loc[df_temp[feature] > max_thresh, feature] = np.nan\n",
    "                        df_temp.loc[df_temp[feature] < min_thresh, feature] = np.nan\n",
    "                        #if output_column is not None and output_column in numeric_columns:\n",
    "                        #    numeric_columns.remove(output_column)\n",
    "                        df_temp = pd.get_dummies(df_temp, drop_first = True)\n",
    "                        imputer = IterativeImputer(max_iter=10, random_state = random_state)\n",
    "                        df_temp = imputer.fit_transform(df_temp)\n",
    "                        df[feature] = df_temp[feature]\n",
    "\n",
    "            else:\n",
    "                print(f'The feature {feature} is not numeric and was therefore ignored')\n",
    "\n",
    "        else:\n",
    "            print(f'A {feature} não foi encontrada no dataframe e foi ignorada')\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71104cb1",
   "metadata": {},
   "source": [
    "## Refactored Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2420d081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_outlier_threshold(df: pd.DataFrame, feature: str, \n",
    "                               skew_thresold: float = 1) -> tuple[float, float]: \n",
    "    \"\"\"\n",
    "    Calculate the inferior and superior thresholds for outlier detection.\n",
    "    Values above max_thresh and values below min_thresh are considered outliers\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the feature.\n",
    "        feature (str): The name of the feature to be processed.\n",
    "        skew_thresold (float): The skewness threshold used to determine whether the distribution is normal or not.\n",
    "\n",
    "    Returns:    \n",
    "        tuple: A tuple containing the inferior and superior thresholds for outlier detection.\n",
    "    \"\"\"\n",
    "    skew = df[feature].skew()\n",
    "    if skew > -1 * skew_thresold and skew < skew_thresold:\n",
    "        #empirical rule to detect outliers in normal distributions\n",
    "        min_thresh = df[feature].mean() - 3 * df[feature].std()\n",
    "        max_thresh = df[feature].mean() + 3 * df[feature].std()\n",
    "    else: \n",
    "        #apply the Tukey rule to detect outliers in distributions that are not normal\n",
    "        q1 = df[feature].quantile(0.25)\n",
    "        q3 = df[feature].quantile(0.75)\n",
    "        iqr = q3 - q1 #interquartile range\n",
    "        max_thresh = q3 + 1.5 * (iqr) \n",
    "        min_thresh = q1 - 1.5 * (iqr)\n",
    "    \n",
    "    return (min_thresh, max_thresh)    \n",
    "\n",
    "def clean_outliers(df: pd.DataFrame, features_list: list = None, \n",
    "                   outlier_treatment: str = None, output_column: str = None, \n",
    "                   skew_thresold: float = 1) -> pd.DataFrame:\n",
    "    '''\n",
    "    Detect and treat outliers. Two criteria will be used to detect outliers:\n",
    "        - empirical rule to detect outliers in normal distributions;\n",
    "        - Tukey rule to detect outliers in distributions that are not normal.\n",
    "    A distribution will be considered normal when its skewness is between -1 * skew_thresold and skew_thresold.\n",
    "    One of the two criteria will be used to calculate max_thresh and min_thresh. Values above max_thresh and \n",
    "    values below min_thresh are considered outliers.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe to be cleaned.\n",
    "    features_list : list, optional\n",
    "        The list of features to be cleaned, by default, is None. If None, the function will clean all features.\n",
    "    outlier_treatment : str, optional\n",
    "        The treatment to be applied to outliers, by default, None. Can be 'remove'; 'replace'; 'impute', or None:\n",
    "            - remove: rows containing outliers are completely removed;\n",
    "            - replace: outliers above max_thresh and outliers below min_thresh are replaced by max_thresh and min_thresh, respectively;\n",
    "            - impute: outliers above max_thresh and outliers below min_thresh are imputed using the Iterative imputer method form scikit-learn;\n",
    "            - None: no treatment is applied to outliers.\n",
    "    output_column : str, optional\n",
    "        The name of the output column, by default is None. The output column will not be used when calculating the values to be imputed. \n",
    "        If None, it is considered that the output column is not in df.\n",
    "    skew_thresold : float, optional\n",
    "        The skewness threshold for a distribution to be considered normal, by default 1.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The cleaned dataframe.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    df = df.copy()\n",
    "    df = df.dropna()\n",
    "    \n",
    "    if features_list is None:\n",
    "        features_list = df.columns.to_list()\n",
    "\n",
    "    if outlier_treatment not in ['remove', 'replace', 'impute', None]:\n",
    "        print(f'The outlier_treatment {outlier_treatment} is not valid. No treatment will be applied to outliers.')\n",
    "        outlier_treatment = None\n",
    "\n",
    "    #remove output_column from features_list. The output column can not be used when calculating the values to be imputed\n",
    "    if output_column is not None and output_column in features_list:\n",
    "        features_list_impute_method = features_list.copy()\n",
    "        features_list_impute_method.remove(output_column)\n",
    "    else:\n",
    "        features_list_impute_method = features_list\n",
    " \n",
    "\n",
    "    for feature in features_list:\n",
    "        #test whether the feature is in the dataframe\n",
    "        if feature in df.columns:\n",
    "            #only numeric columns will be cleaned\n",
    "            if pd.api.types.is_numeric_dtype(df[feature]):\n",
    "\n",
    "                #test whether the feature has only one unique value\n",
    "                if df[feature].nunique() == 1:\n",
    "                    print(f'The feature {feature} has only one unique value and was therefore ignored.')\n",
    "\n",
    "                #test whether the feature is binary (only true or false values)\n",
    "                elif (set(df[feature].dropna().unique()).issubset({0, 1}) or\n",
    "                        set(df[feature].dropna().unique()).issubset({True, False})):\n",
    "                    print(f'The feature {feature} is binary (only true or false values) and was therefore ignored.')\n",
    "\n",
    "                # look for outliers\n",
    "                else:\n",
    "                    #calculate max_thresh and min_thresh\n",
    "                    \n",
    "                    min_thresh, max_thresh = calculate_outlier_threshold(df, feature, skew_thresold)\n",
    "                    \n",
    "\n",
    "                    #values above max_thresh and values below min_thresh are considered outliers\n",
    "                    count_max_outlier = len(df.loc[df[feature] > max_thresh])\n",
    "                    count_min_outlier = len(df.loc[df[feature] < min_thresh])\n",
    "                    print(f'The feature {feature} has {count_max_outlier} values above {max_thresh}')\n",
    "                    print(f'The feature {feature} has {count_min_outlier} values below {min_thresh}')\n",
    "\n",
    "                    has_outliers = count_max_outlier > 0 or count_min_outlier > 0\n",
    "\n",
    "                    if not has_outliers:                  \n",
    "                        continue\n",
    "\n",
    "                    if outlier_treatment == 'remove':\n",
    "                        df = df[(df[feature] >= min_thresh) & (df[feature] <= max_thresh)]\n",
    "                        print(f'{feature}: outliers removed')\n",
    "\n",
    "                    elif outlier_treatment == 'replace':\n",
    "                        if not pd.api.types.is_float_dtype(df[feature]):\n",
    "                            df[feature] = df[feature].astype(float) #convert to float\n",
    "                        print(f'{feature}: outliers replaced')\n",
    "                        df.loc[df[feature] > max_thresh, feature] = max_thresh\n",
    "                        df.loc[df[feature] < min_thresh, feature] = min_thresh\n",
    "\n",
    "                    elif outlier_treatment == 'impute':\n",
    "                        df_temp = df[features_list_impute_method].copy()\n",
    "                        df_temp.loc[df_temp[feature] > max_thresh, feature] = np.nan\n",
    "                        df_temp.loc[df_temp[feature] < min_thresh, feature] = np.nan\n",
    "\n",
    "                        df_temp = pd.get_dummies(df_temp, drop_first = True)\n",
    "                        imputer = IterativeImputer(max_iter=10, random_state = random_state)\n",
    "                        df_temp = imputer.fit_transform(df_temp)\n",
    "                        df[feature] = df_temp[feature]\n",
    "\n",
    "            else:\n",
    "                print(f'The feature {feature} is not numeric and was therefore ignored')\n",
    "\n",
    "        else:\n",
    "            print(f'A {feature} não foi encontrada no dataframe e foi ignorada')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "100ea596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature Unnamed: 0 has 0 values above 637.8666447115643\n",
      "The feature Unnamed: 0 has 0 values below -171.86664471156428\n",
      "The feature Player Name is not numeric and was therefore ignored\n",
      "The feature Salary has 48 values above 23909927.25\n",
      "The feature Salary has 0 values below -11493762.75\n",
      "Salary: outliers removed\n",
      "The feature Position is not numeric and was therefore ignored\n",
      "The feature Age has 2 values above 37.69698176195109\n",
      "The feature Age has 0 values below 13.071514658096635\n",
      "Age: outliers removed\n",
      "The feature Team is not numeric and was therefore ignored\n",
      "The feature GP has 0 values above 123.12820598410082\n",
      "The feature GP has 0 values below -28.912378645971323\n",
      "The feature GS has 10 values above 77.5\n",
      "The feature GS has 0 values below -46.5\n",
      "GS: outliers removed\n",
      "The feature MP has 0 values above 44.164263305748435\n",
      "The feature MP has 0 values below -7.982936524421657\n",
      "The feature FG has 19 values above 7.15\n",
      "The feature FG has 0 values below -2.0500000000000003\n",
      "FG: outliers removed\n",
      "The feature FGA has 5 values above 15.114829021283654\n",
      "The feature FGA has 0 values below -4.157097062520767\n",
      "FGA: outliers removed\n",
      "The feature FG% has 3 values above 0.8153836507834311\n",
      "The feature FG% has 5 values below 0.10785718691290391\n",
      "FG%: outliers removed\n",
      "The feature 3P has 2 values above 2.7825415286730433\n",
      "The feature 3P has 0 values below -1.175589657015289\n",
      "3P: outliers removed\n",
      "The feature 3PA has 0 values above 7.148517045330687\n",
      "The feature 3PA has 0 values below -2.671635324900578\n",
      "The feature 3P% has 4 values above 0.7366733824944738\n",
      "The feature 3P% has 0 values below -0.08795712905094771\n",
      "3P%: outliers removed\n",
      "The feature 2P has 7 values above 4.65\n",
      "The feature 2P has 0 values below -1.35\n",
      "2P: outliers removed\n",
      "The feature 2PA has 1 values above 8.794711699951616\n",
      "The feature 2PA has 0 values below -2.7157344272243438\n",
      "2PA: outliers removed\n",
      "The feature 2P% has 5 values above 0.9192718449603812\n",
      "The feature 2P% has 7 values below 0.14177113498231209\n",
      "2P%: outliers removed\n",
      "The feature eFG% has 2 values above 0.7714455923930572\n",
      "The feature eFG% has 5 values below 0.29068497140516225\n",
      "eFG%: outliers removed\n",
      "The feature FT has 11 values above 2.6125\n",
      "The feature FT has 0 values below -0.8875\n",
      "FT: outliers removed\n",
      "The feature FTA has 0 values above 3.3839337474002367\n",
      "The feature FTA has 0 values below -1.054153183136914\n",
      "The feature FT% has 0 values above 1.05625\n",
      "The feature FT% has 6 values below 0.44825000000000015\n",
      "FT%: outliers removed\n",
      "The feature ORB has 16 values above 2.05\n",
      "The feature ORB has 0 values below -0.7499999999999998\n",
      "ORB: outliers removed\n",
      "The feature DRB has 3 values above 5.088643698257087\n",
      "The feature DRB has 0 values below -0.9023423283940732\n",
      "DRB: outliers removed\n",
      "The feature TRB has 0 values above 6.46603100499499\n",
      "The feature TRB has 0 values below -0.9968268527458561\n",
      "The feature AST has 21 values above 3.6999999999999997\n",
      "The feature AST has 0 values below -1.0999999999999999\n",
      "AST: outliers removed\n",
      "The feature STL has 9 values above 1.2999999999999998\n",
      "The feature STL has 0 values below -0.3\n",
      "STL: outliers removed\n",
      "The feature BLK has 9 values above 0.8500000000000001\n",
      "The feature BLK has 0 values below -0.3500000000000001\n",
      "BLK: outliers removed\n",
      "The feature TOV has 1 values above 1.8200642201413997\n",
      "The feature TOV has 0 values below -0.36486422014139974\n",
      "TOV: outliers removed\n",
      "The feature PF has 2 values above 3.2217405018302134\n",
      "The feature PF has 0 values below -0.2305758431956757\n",
      "PF: outliers removed\n",
      "The feature PTS has 4 values above 14.750231933885484\n",
      "The feature PTS has 0 values below -2.854685375181031\n",
      "PTS: outliers removed\n",
      "The feature Player-additional is not numeric and was therefore ignored\n"
     ]
    }
   ],
   "source": [
    "nba_clenaed = clean_outliers(nba, output_column = 'Salary', skew_thresold = 1, outlier_treatment = 'remove')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7947fbb2",
   "metadata": {},
   "source": [
    "# Managing Outliers all features at once using DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ceb2ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_eps_dbscan(df: pd.DataFrame, distance_metric: str = 'manhattan', \n",
    "                      min_samples: int = 5, eps_step : float = 0.01, desired_percentage_outliers : float = 0.02 ):\n",
    "\n",
    "    '''\n",
    "    Function to look for the best eps value for DBSCAN. Different eps values are tested to determine the proportion of outliers they produce.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe to be cleaned.\n",
    "    distance_metric : str, optional\n",
    "        The distance metric to be used in DBSCAN. The default is 'manhattan'. This metric is used by \n",
    "        DBSCAN to calculate the distance between points.\n",
    "    min_samples : int, optional          \n",
    "        The minimum samples to be used in DBSCAN. The default is 5. It is the maximum distance between \n",
    "        two samples for one to be considered as in the neighborhood of the other.The larger the eps value, \n",
    "        the fewer outliers there will be.\n",
    "    eps_step : float, optional\n",
    "        The step size to be used in the eps search. The default is 0.01. The step_size is used to increment\n",
    "        the eps value.    \n",
    "    desired_percentage_outliers : float, optional\n",
    "        The desired percentage of outliers to be removed. The default is 0.02. The function will return the eps value\n",
    "        that produces the desired percentage of outliers.\n",
    "        \n",
    "    Returns\n",
    "    ------- \n",
    "    eps_percentage_outliers : pandas DataFrame\n",
    "        A dataframe with the eps values and the percentage of outliers they produce.\n",
    "    desired_percentage_outliers : float\n",
    "        The eps value that produces the desired percentage of outliers.              \n",
    "    '''\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "\n",
    "    #remove NaN\n",
    "    initial_number_of_columns = df.shape[1]\n",
    "    initial_number_of_rows = df.shape[0]\n",
    "    initial_number_of_nan = df_temp.isna().sum().sum()  \n",
    "    print(f'Number of missing values: {initial_number_of_nan}')\n",
    "\n",
    "    df_temp = df_temp.dropna(axis = 'columns', how = 'all')\n",
    "    df_temp = df_temp.dropna(axis = 'rows', how = 'any')\n",
    "\n",
    "    final_number_of_columns = df_temp.shape[1]\n",
    "    final_number_of_rows = df_temp.shape[0]\n",
    "\n",
    "    print(f'Number of columns removed: {initial_number_of_columns - final_number_of_columns}')\n",
    "    print(f'Number of rows removed: {initial_number_of_rows - final_number_of_rows}')\n",
    "    print(f'Number of missing values after cleaning: {df_temp.isna().sum().sum()}')\n",
    "\n",
    "    #Transform categorical variables \n",
    "    df_temp = pd.get_dummies(df_temp, drop_first = True)\n",
    "\n",
    "    #Min max Scaler\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    df_temp = min_max_scaler.fit_transform(df_temp)\n",
    "\n",
    "    #test DBSCAN using different eps to determine the number of outliers they produce\n",
    "    eps_percentage_outliers = {'eps' : [],\n",
    "                               'percentage_outliers(%)' : []}\n",
    "    num_outliers = len(df_temp)\n",
    "    eps = 0\n",
    "    while num_outliers > 0:\n",
    "        eps += eps_step\n",
    "        dba = DBSCAN(eps = eps, min_samples = min_samples, metric=distance_metric, n_jobs = -1)\n",
    "        dba.fit(df_temp)\n",
    "        labels = dba.labels_\n",
    "        num_outliers = np.count_nonzero(labels == -1)\n",
    "        eps_percentage_outliers['eps'].append(eps)\n",
    "        eps_percentage_outliers['percentage_outliers(%)'].append(round(100 * num_outliers/len(df_temp), 2))\n",
    "    eps_percentage_outliers = pd.DataFrame(eps_percentage_outliers) \n",
    "    \n",
    "    #look for the eps value that produces the desired percentage of outliers\n",
    "    eps_percentage_outliers['diff'] = eps_percentage_outliers['percentage_outliers(%)'] - 100 * desired_percentage_outliers\n",
    "    eps_percentage_outliers['diff'] = np.abs(eps_percentage_outliers['diff'])\n",
    "    idx_min = eps_percentage_outliers['diff'].idxmin()\n",
    "    desired_eps = round(eps_percentage_outliers.loc[idx_min, 'eps'], 2)\n",
    "    percentage_outliers = eps_percentage_outliers.loc[idx_min, 'percentage_outliers(%)']\n",
    "\n",
    "    #plot a lineplot with the eps values and the percentage of outliers they produce\n",
    "    ax = sns.lineplot(data = eps_percentage_outliers , x = 'eps', y = 'percentage_outliers(%)')\n",
    "    plt.scatter(desired_eps, percentage_outliers)\n",
    "    text = f'eps = {desired_eps} \\n'\n",
    "    text += f'percentage_outliers(%) = {percentage_outliers}'\n",
    "    plt.annotate(text, \n",
    "                xy=(desired_eps, percentage_outliers), \n",
    "                xytext=(desired_eps + 0.1, percentage_outliers + 0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray'))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return eps_percentage_outliers, desired_eps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6660aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outliers_using_DBscan(df: pd.DataFrame, eps: float, distance_metric: str = 'manhattan', \n",
    "                                min_samples: int = 5):\n",
    "    \n",
    "    '''\n",
    "    Funcion to remove outliers using DBSCAN\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas DataFrame\n",
    "        The dataframe to be cleaned.\n",
    "    eps : float\n",
    "        The eps value to be used in DBSCAN. This value is the maximum distance between two samples for one to be \n",
    "        considered as in the neighborhood of the other.\n",
    "    distance_metric : str, optional          \n",
    "        The metric to be used in DBSCAN. The default is 'manhattan'. It is the metric used to calculate the distance between points.\n",
    "    min_samples : int, optional          \n",
    "        The minimum samples to be used in DBSCAN. The default is 5. It is the maximum distance between \n",
    "        two samples for one to be considered as in the neighborhood of the other.The larger the eps value, \n",
    "        the fewer outliers there will be.\n",
    "\n",
    "    Returns\n",
    "    ------- \n",
    "    df : pandas DataFrame\n",
    "        The cleaned dataframe.\n",
    "    '''\n",
    "\n",
    "    df = pd.copy(df)\n",
    "    df_temp = df.copy()\n",
    "\n",
    "    #remove NaN\n",
    "    initial_number_of_columns = df.shape[1]\n",
    "    initial_number_of_rows = df.shape[0]\n",
    "    initial_number_of_nan = df_temp.isna().sum().sum()  \n",
    "    print(f'Number of missing values: {initial_number_of_nan}')\n",
    "\n",
    "    df_temp = df_temp.dropna(axis = 'columns', how = 'all')\n",
    "    df_temp = df_temp.dropna(axis = 'rows', how = 'any')\n",
    "\n",
    "    final_number_of_columns = df_temp.shape[1]\n",
    "    rows_no_nan = df_temp.shape[0]\n",
    "\n",
    "    print(f'Number of columns removed: {initial_number_of_columns - final_number_of_columns}')\n",
    "    print(f'Number of rows removed: {initial_number_of_rows - rows_no_nan}')\n",
    "    print(f'Number of missing values after cleaning: {df_temp.isna().sum().sum()}')\n",
    "\n",
    "    #Transform categorical variables \n",
    "    df_temp = pd.get_dummies(df_temp, drop_first = True)\n",
    "\n",
    "    #Min max Scaler\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    df_temp = min_max_scaler.fit_transform(df_temp)\n",
    "\n",
    "    #DBSCAN to look for outliers\n",
    "    dba = DBSCAN(eps = eps, min_samples = min_samples, metric=distance_metric, n_jobs = -1)\n",
    "    dba.fit(df_temp)\n",
    "    labels = dba.labels_\n",
    "    df_temp['labels'] = labels\n",
    "    number_outliers = np.count_nonzero(labels == -1)\n",
    "    print(f'Number of outliers: {number_outliers}')\n",
    "\n",
    "    #remove outliers\n",
    "    index_outliers = df_temp[df_temp['labels'] == -1].index\n",
    "    df = df.drop(index_outliers)\n",
    "\n",
    "    print(f'Percentage of rows removed: {(number_outliers / rows_no_nan) * 100}%')    \n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automacao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
